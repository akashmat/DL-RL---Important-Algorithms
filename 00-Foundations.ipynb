{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Dict\n",
    "import numpy as np\n",
    "\n",
    "# A Function takes in an ndarray as an argument and produces an ndarray\n",
    "Array_Function = Callable[[np.ndarray], np.ndarray]\n",
    "Chain = List[Array_Function]\n",
    "\n",
    "\"\"\"type Layer = Callable\n",
    "\n",
    "class NN:\n",
    "    def __init__(self,\n",
    "                 layers: List[Layer]):\n",
    "        pass\n",
    "        \n",
    "\"\"\"\n",
    "def square(x: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Square each element in the input ndarray.\n",
    "    '''\n",
    "    return np.power(x, 2)\n",
    "\n",
    "def leaky_relu(x: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Apply \"Leaky ReLU\" function to each element in ndarray.\n",
    "    '''\n",
    "    return np.maximum(0.2 * x, x)\n",
    "\n",
    "\n",
    "def derive(func: Callable[[np.ndarray], np.ndarray],\n",
    "           input_: np.ndarray, \n",
    "           delta: float = 0.001) -> np.ndarray:\n",
    "    return (func(input_ + delta) - func(input_ - delta))/(2 * delta)\n",
    "\n",
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    “Apply the sigmoid function to each element in the input ndarray.”\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def chain_length_2(chain: Chain,\n",
    "                   x: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Evaluates two functions in a row, in a \"Chain\".\n",
    "    '''\n",
    "    assert len(chain) == 2, \\\n",
    "    \"Length of input 'chain' should be 2\"\n",
    "\n",
    "    f1 = chain[0]\n",
    "    f2 = chain[1]\n",
    "\n",
    "    return f2(f1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "def forward_linear_regression(X_batch: np.ndarray,\n",
    "                              y_batch: np.ndarray,\n",
    "                              weights: Dict[str, np.ndarray]) -> Tuple[float, Dict[str, np.ndarray]]:\n",
    "    \n",
    "    assert X_batch.shape[0] == y_batch.shape[0]\n",
    "    assert X_batch.shape[1] == weights['W'].shape[0]\n",
    "    #B is a 1x1 ndarray\n",
    "    assert weights['B'].shape[0] == weights['B'].shape[1] == 1\n",
    "\n",
    "    N = np.dot(X_batch, weights['W'])\n",
    "    P = N + weights['B']\n",
    "\n",
    "    loss = np.mean(np.power(y_batch - P, 2))\n",
    "\n",
    "    forward_info: Dict[str, np.ndarray] = {}\n",
    "    forward_info['X'] = X_batch\n",
    "    forward_info['N'] = N\n",
    "    forward_info['P'] = P\n",
    "    forward_info['y'] = y_batch\n",
    "\n",
    "    return loss, forward_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_loss(X: np.ndarray,\n",
    "                 y: np.ndarray,\n",
    "                 weights: Dict[str, np.ndarray]\n",
    "                 )-> Tuple[Dict[str, np.ndarray], float]:\n",
    "    '''\n",
    "    Compute the forward pass and the loss for the step-by-step\n",
    "    neural network model.\n",
    "    '''\n",
    "    M1 = np.dot(X, weights['W1'])\n",
    "    N1 = M1 + weights['B1']\n",
    "    O1 = sigmoid(N1)\n",
    "    M2 = np.dot(O1, weights['W2'])\n",
    "    P = M2 + weights['B2']\n",
    "    loss = np.mean(np.power(y - P, 2))\n",
    "    forward_info: Dict[str, np.ndarray] = {}\n",
    "    forward_info['X'] = X\n",
    "    forward_info['M1'] = M1\n",
    "    forward_info['N1'] = N1\n",
    "    forward_info['O1'] = O1\n",
    "    forward_info['M2'] = M2\n",
    "    forward_info['P'] = P\n",
    "    forward_info['y'] = y\n",
    "\n",
    "    return forward_info, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_gradients(forward_info: Dict[str, np.ndarray],\n",
    "                   weights: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "    '''\n",
    "    Compute dLdW and dLdB for the step-by-step linear regression model.\n",
    "    '''\n",
    "    batch_size = forward_info['X'].shape[0]\n",
    "\n",
    "    dLdP = -2 * (forward_info['y'] - forward_info['P'])\n",
    "\n",
    "    dPdN = np.ones_like(forward_info['N'])\n",
    "\n",
    "    dPdB = np.ones_like(weights['B'])\n",
    "\n",
    "    dLdN = dLdP * dPdN\n",
    "\n",
    "    dNdW = np.transpose(forward_info['X'], (1, 0))\n",
    "\n",
    "    # need to use matrix multiplication here,\n",
    "    # with dNdW on the left (see note at the end of last chapter)\n",
    "    dLdW = np.dot(dNdW, dLdN)\n",
    "\n",
    "    # need to sum along dimension representing the batch size\n",
    "    # (see note near the end of this chapter)\n",
    "    dLdB = (dLdP * dPdB).sum(axis=0)\n",
    "\n",
    "    loss_gradients: Dict[str, np.ndarray] = {}\n",
    "    loss_gradients['W'] = dLdW\n",
    "    loss_gradients['B'] = dLdB\n",
    "\n",
    "    return loss_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forward_info, loss = forward_loss(X_batch, y_batch, weights)\n",
    "\n",
    "loss_grads = loss_gradients(forward_info, weights)\n",
    "\n",
    "for key in weights.keys():\n",
    "    weights[key] -= learning_rate * loss_grads[key]\n",
    "\n",
    "\n",
    "def predict(X: np.ndarray,\n",
    "            weights: Dict[str, np.ndarray]) -> np.ndarray:\n",
    "    '''\n",
    "    Generate predictions from the step-by-step neural network model.\n",
    "    '''\n",
    "    M1 = np.dot(X, weights['W1'])\n",
    "\n",
    "    N1 = M1 + weights['B1']\n",
    "\n",
    "    O1 = sigmoid(N1)\n",
    "\n",
    "    M2 = np.dot(O1, weights['W2'])\n",
    "\n",
    "    P = M2 + weights['B2']\n",
    "\n",
    "    return P"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
